import os
import subprocess
import threading
import tkinter as tk
from tkinter import messagebox, simpledialog
from tkinter.scrolledtext import ScrolledText

from openai import OpenAI
from pydub import AudioSegment

# ‡πÄ‡∏û‡∏¥‡πà‡∏° import ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Whisper Local
try:
    import whisper
    WHISPER_LOCAL_AVAILABLE = True
except ImportError:
    WHISPER_LOCAL_AVAILABLE = False




# Whisper Local Model (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
whisper_model = None

OUTPUT_FOLDER = "downloads"
os.makedirs(OUTPUT_FOLDER, exist_ok=True)

def download_audio(url, callback):
    """‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á mp3 ‡∏à‡∏≤‡∏Å yt-dlp (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö YouTube, TikTok ‡πÅ‡∏•‡∏∞‡∏≠‡∏∑‡πà‡∏ô‡πÜ)"""
    try:
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö filesystem
        output_template = os.path.join(OUTPUT_FOLDER, "%(title).100s.%(ext)s")
        command = [
            "yt-dlp",
            "-x",
            "--audio-format", "mp3",
            "-o", output_template,
            url,
            "--no-warnings",  
            "--restrict-filenames" 
        ]
        
        print(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏£‡∏±‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á: {' '.join(command)}")
        result = subprocess.run(command, check=True, capture_output=True, text=True)
        print(f"‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå: {result.stdout}")
        
        # ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå mp3 ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå
        files = [f for f in os.listdir(OUTPUT_FOLDER) if f.endswith(".mp3")]
        if not files:
            raise Exception("‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î")
        latest_file = max(files, key=lambda f: os.path.getctime(os.path.join(OUTPUT_FOLDER, f)))
        callback(os.path.join(OUTPUT_FOLDER, latest_file))
    except subprocess.CalledProcessError as e:
        error_msg = f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏î‡πâ\nReturn code: {e.returncode}"
        if hasattr(e, 'stderr') and e.stderr:
            error_msg += f"\nError: {e.stderr}"
        messagebox.showerror("Download Error", f"{error_msg}\n\n‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö:\n- ‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n- ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏≠‡∏¥‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡πÄ‡∏ô‡πá‡∏ï‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n- ‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÄ‡∏õ‡πá‡∏ô Private ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà")
    except Exception as e:
        messagebox.showerror("Download Error", f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")

def transcribe_with_openai(audio_path):
    """‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢ OpenAI Whisper API"""
    try:
        with open(audio_path, "rb") as audio_file:
            # ‡πÉ‡∏ä‡πâ OpenAI Whisper API ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language="th",  # ‡∏£‡∏∞‡∏ö‡∏∏‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
                response_format="verbose_json",  # ‡πÉ‡∏´‡πâ‡∏™‡πà‡∏á timestamps ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤
                timestamp_granularities=["segment"]
            )
        return transcript
    except Exception as e:
        messagebox.showerror("Transcription Error", f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏î‡πâ\n{e}")
        return None

def transcribe_with_whisper_local(audio_path, model_size="large-v3"):
    """‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢ Whisper Local (‡∏ü‡∏£‡∏µ ‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ GPU)"""
    global whisper_model
    try:
        # ‡πÇ‡∏´‡∏•‡∏î model ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÇ‡∏´‡∏•‡∏î
        if whisper_model is None:
            messagebox.showinfo("Loading Model", f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î Whisper {model_size} model... ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏≠‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà")
            whisper_model = whisper.load_model(model_size)
        
        # ‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á
        result = whisper_model.transcribe(
            audio_path, 
            language="th",
            word_timestamps=True,
            verbose=True
        )
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö OpenAI
        segments = []
        for i, segment in enumerate(result.get('segments', [])):
            segments.append({
                'start': segment.get('start', 0),
                'end': segment.get('end', 0),
                'text': segment.get('text', '').strip()
            })
        
        return {'segments': segments}
    except Exception as e:
        messagebox.showerror("Local Whisper Error", f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢ Whisper Local ‡πÑ‡∏î‡πâ\n{e}")
        return None

def transcribe_with_enhanced_openai(audio_path):
    """‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢ OpenAI ‡πÅ‡∏ö‡∏ö‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÉ‡∏´‡πâ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏∂‡πâ‡∏ô"""
    try:
        with open(audio_path, "rb") as audio_file:
            # ‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language="th",
                response_format="verbose_json",
                timestamp_granularities=["segment"],
                # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥
                prompt="‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡πâ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î",  # ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ AI ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ö‡∏£‡∏¥‡∏ö‡∏ó
                temperature=0.0  # ‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡πà‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥
            )
        return transcript
    except Exception as e:
        messagebox.showerror("Enhanced Transcription Error", f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏î‡πâ\n{e}")
        return None

def transcribe_and_show(audio_path, text_widget, segments_listbox, method="openai"):
    """‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á segment"""
    if method == "openai":
        result = transcribe_with_openai(audio_path)
    elif method == "enhanced":
        result = transcribe_with_enhanced_openai(audio_path)
    elif method == "local" and WHISPER_LOCAL_AVAILABLE:
        result = transcribe_with_whisper_local(audio_path)
    else:
        messagebox.showerror("Error", "‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
        return []
    
    if not result:
        return []
    
    # ‡πÅ‡∏õ‡∏•‡∏á response object ‡πÄ‡∏õ‡πá‡∏ô dictionary ‡∏´‡∏≤‡∏Å‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
    if hasattr(result, 'model_dump'):
        result_dict = result.model_dump()
    elif hasattr(result, 'dict'):
        result_dict = result.dict()
    else:
        result_dict = result
    
    segments = result_dict.get('segments', [])
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏á‡πÉ‡∏ô widget
    text_widget.config(state=tk.NORMAL)
    text_widget.delete("1.0", tk.END)
    segments_listbox.delete(0, tk.END)

    for i, seg in enumerate(segments):
        start = seg.get('start', 0)
        end = seg.get('end', 0)
        text = seg.get('text', '').strip()
        text_widget.insert(tk.END, f"[{i}] ({start:.2f}s - {end:.2f}s): {text}\n")
        segments_listbox.insert(tk.END, f"{i}: {text}")

    text_widget.config(state=tk.DISABLED)
    return segments

def cut_audio_segment(audio_path, segment, output_name, delete_original=False):
    """‡∏ï‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å segment ‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà"""
    try:
        start_ms = int(segment.get('start', 0) * 1000)
        end_ms = int(segment.get('end', 0) * 1000)

        audio = AudioSegment.from_file(audio_path)
        clip = audio[start_ms:end_ms]

        clip.export(output_name, format="mp3")
        
        success_msg = f"‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ï‡∏±‡∏î‡∏ï‡πà‡∏≠: {output_name}"
        
        # ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
        if delete_original:
            try:
                os.remove(audio_path)
                success_msg += f"\nüóëÔ∏è ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡πÅ‡∏•‡πâ‡∏ß: {os.path.basename(audio_path)}"
            except Exception as e:
                success_msg += f"\n‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡πÑ‡∏î‡πâ: {e}"
        
        messagebox.showinfo("Success", success_msg)
        
    except Exception as e:
        messagebox.showerror("Error", f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏î‡πâ: {e}")

def validate_url(url):
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏∏‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á URL"""
    url = url.strip().lower()
    
    # ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ domains ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö
    supported_platforms = {
        'youtube.com': 'YouTube',
        'youtu.be': 'YouTube',
        'm.youtube.com': 'YouTube',
        'tiktok.com': 'TikTok',
        'www.tiktok.com': 'TikTok',
        'vm.tiktok.com': 'TikTok',
        'vt.tiktok.com': 'TikTok',
        'm.tiktok.com': 'TikTok'
    }
    
    for domain, platform in supported_platforms.items():
        if domain in url:
            return True, platform
    
    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö platform ‡∏ó‡∏µ‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å ‡πÅ‡∏ï‡πà‡πÄ‡∏õ‡πá‡∏ô URL ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡∏î‡∏π
    if url.startswith(('http://', 'https://')):
        return True, '‡∏≠‡∏∑‡πà‡∏ô‡πÜ'
    
    return False, None

def get_platform_emoji(platform):
    """‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô emoji ‡∏ï‡∏≤‡∏° platform"""
    emojis = {
        'YouTube': 'üî¥',
        'TikTok': '‚ö´',
        '‡∏≠‡∏∑‡πà‡∏ô‡πÜ': 'üåê'
    }
    return emojis.get(platform, 'üåê')

def parse_multiple_urls(text):
    """‡πÅ‡∏¢‡∏Å‡∏´‡∏•‡∏≤‡∏¢ URL ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°"""
    import re
    
    # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ URLs ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
    url_pattern = r'https?://[^\s\n]+'
    urls = re.findall(url_pattern, text)
    
    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ URLs ‡πÅ‡∏ö‡∏ö regex ‡πÉ‡∏´‡πâ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
    if not urls:
        lines = [line.strip() for line in text.split('\n') if line.strip()]
        urls = [line for line in lines if line.startswith(('http://', 'https://'))]
    
    return urls

def download_multiple_audio(urls, progress_callback, completion_callback):
    """‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢ URL"""
    downloaded_files = []
    total_urls = len(urls)
    
    for i, url in enumerate(urls):
        try:
            # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞
            is_valid, platform = validate_url(url)
            if not is_valid:
                progress_callback(i + 1, total_urls, f"‚ùå ‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á: {url[:50]}...")
                continue
            
            platform_emoji = get_platform_emoji(platform)
            progress_callback(i + 1, total_urls, f"‚è≥ {platform_emoji} ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å {platform}...")
            
            # ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î
            output_template = os.path.join(OUTPUT_FOLDER, f"%(title).100s_clip{i+1}.%(ext)s")
            command = [
                "yt-dlp",
                "-x",
                "--audio-format", "mp3",
                "-o", output_template,
                url,
                "--no-warnings",
                "--restrict-filenames"
            ]
            
            result = subprocess.run(command, check=True, capture_output=True, text=True)
            
            # ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
            files_before = set(f for f in os.listdir(OUTPUT_FOLDER) if f.endswith(".mp3"))
            files_after = set(f for f in os.listdir(OUTPUT_FOLDER) if f.endswith(".mp3"))
            new_files = files_after - files_before
            
            if not new_files:
                # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà ‡πÉ‡∏´‡πâ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ clip{i+1}
                all_files = [f for f in os.listdir(OUTPUT_FOLDER) if f.endswith(".mp3") and f"clip{i+1}" in f]
                if all_files:
                    latest_file = max(all_files, key=lambda f: os.path.getctime(os.path.join(OUTPUT_FOLDER, f)))
                    downloaded_files.append(os.path.join(OUTPUT_FOLDER, latest_file))
                else:
                    # ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
                    all_files = [f for f in os.listdir(OUTPUT_FOLDER) if f.endswith(".mp3")]
                    if all_files:
                        latest_file = max(all_files, key=lambda f: os.path.getctime(os.path.join(OUTPUT_FOLDER, f)))
                        downloaded_files.append(os.path.join(OUTPUT_FOLDER, latest_file))
            else:
                latest_file = list(new_files)[0]
                downloaded_files.append(os.path.join(OUTPUT_FOLDER, latest_file))
            
            progress_callback(i + 1, total_urls, f"‚úÖ {platform_emoji} ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à: {platform}")
            
        except subprocess.CalledProcessError as e:
            progress_callback(i + 1, total_urls, f"‚ùå ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {url[:50]}...")
            continue
        except Exception as e:
            progress_callback(i + 1, total_urls, f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)[:50]}...")
            continue
    
    completion_callback(downloaded_files)

def process_multiple_files(audio_files, method, progress_callback, completion_callback):
    """‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå"""
    all_results = []
    total_files = len(audio_files)
    
    for i, audio_path in enumerate(audio_files):
        try:
            progress_callback(i + 1, total_files, f"‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏ü‡∏•‡πå {i+1}/{total_files}...")
            
            # ‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á
            if method == "openai":
                result = transcribe_with_openai(audio_path)
            elif method == "enhanced":
                result = transcribe_with_enhanced_openai(audio_path)
            elif method == "local" and WHISPER_LOCAL_AVAILABLE:
                result = transcribe_with_whisper_local(audio_path)
            else:
                continue
            
            if result:
                # ‡πÅ‡∏õ‡∏•‡∏á response object ‡πÄ‡∏õ‡πá‡∏ô dictionary ‡∏´‡∏≤‡∏Å‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
                if hasattr(result, 'model_dump'):
                    result_dict = result.model_dump()
                elif hasattr(result, 'dict'):
                    result_dict = result.dict()
                else:
                    result_dict = result
                
                segments = result_dict.get('segments', [])
                all_results.append({
                    'file': os.path.basename(audio_path),
                    'path': audio_path,
                    'segments': segments
                })
            
            progress_callback(i + 1, total_files, f"‚úÖ ‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏™‡∏£‡πá‡∏à ‡πÑ‡∏ü‡∏•‡πå {i+1}/{total_files}")
            
        except Exception as e:
            progress_callback(i + 1, total_files, f"‚ùå ‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‡πÑ‡∏ü‡∏•‡πå {i+1}")
            continue
    
    completion_callback(all_results)

def setup_api_key():
    """‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ API Key ‡∏ú‡πà‡∏≤‡∏ô dialog"""
    global client
    try:
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ API key ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
        if not hasattr(client, 'api_key') or client.api_key == "your-api-key-here" or not client.api_key:
            api_key = simpledialog.askstring(
                show='*'
            )
            if api_key:
                client = OpenAI(api_key=api_key)
                messagebox.showinfo("Success", "‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ API Key ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢!")
                return True
            else:
                messagebox.showerror("Error", "‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏™‡πà API Key ‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
                return False
        return True
    except Exception as e:
        api_key = simpledialog.askstring(
            "OpenAI API Key", 
            "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà OpenAI API Key:\n(‡∏´‡∏≤‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å https://platform.openai.com/api-keys)",
            show='*'
        )
        if api_key:
            client = OpenAI(api_key=api_key)
            messagebox.showinfo("Success", "‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ API Key ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢!")
            return True
        else:
            messagebox.showerror("Error", "‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏™‡πà API Key ‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
            return False

def on_download_click():
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö URL ‡∏Å‡πà‡∏≠‡∏ô
    url_text = url_entry.get("1.0", tk.END).strip()
    if not url_text:
        messagebox.showerror("Error", "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏Å‡πà‡∏≠‡∏ô")
        return
    
    # ‡πÅ‡∏¢‡∏Å‡∏´‡∏•‡∏≤‡∏¢ URLs
    urls = parse_multiple_urls(url_text)
    if not urls:
        messagebox.showerror("Error", "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á\n‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö: YouTube, TikTok ‡πÅ‡∏•‡∏∞‡∏≠‡∏∑‡πà‡∏ô‡πÜ")
        return
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô URLs
    if len(urls) > 20:
        response = messagebox.askyesno(
            "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÄ‡∏¢‡∏≠‡∏∞", 
            f"‡∏û‡∏ö {len(urls)} ‡∏•‡∏¥‡∏á‡∏Å‡πå ‡∏ã‡∏∂‡πà‡∏á‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏≤‡∏ô\n‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≠‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà?"
        )
        if not response:
            return
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö
    status_label.config(text=f"üîç ‡∏û‡∏ö {len(urls)} ‡∏•‡∏¥‡∏á‡∏Å‡πå")
    window.update()
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö API Key ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö OpenAI methods
    selected_method = transcription_method.get()
    if selected_method in ["openai", "enhanced"] and not setup_api_key():
        return

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ Whisper Local ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    if selected_method == "local" and not WHISPER_LOCAL_AVAILABLE:
        response = messagebox.askyesno(
            "Whisper Local ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô",
            "‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á openai-whisper ‡∏Å‡πà‡∏≠‡∏ô\n‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà?"
        )
        if response:
            install_whisper_local()
        return

    method_text = {
        "openai": "OpenAI Whisper API",
        "enhanced": "OpenAI Whisper (Enhanced)",
        "local": "Whisper Local (Large-v3)"
    }

    # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
    def download_progress(current, total, message):
        status_label.config(text=f"üì• [{current}/{total}] {message}")
        window.update()
    
    def download_complete(audio_files):
        if not audio_files:
            status_label.config(text="‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏î‡πÑ‡∏î‡πâ")
            return
        
        status_label.config(text=f"‚úÖ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à {len(audio_files)} ‡πÑ‡∏ü‡∏•‡πå")
        window.update()
        
        # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á
        def transcribe_progress(current, total, message):
            status_label.config(text=f"üé§ [{current}/{total}] {message}")
            window.update()
        
        def transcribe_complete(results):
            if not results:
                status_label.config(text="‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏î‡πÑ‡∏î‡πâ")
                return
            
            # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
            display_multiple_results(results)
            status_label.config(text=f"‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! ‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏î‡πâ {len(results)} ‡πÑ‡∏ü‡∏•‡πå")
            
            global all_results_global
            all_results_global = results
        
        # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÉ‡∏ô‡πÄ‡∏ò‡∏£‡∏î‡πÅ‡∏¢‡∏Å
        def transcribe_task():
            process_multiple_files(audio_files, selected_method, transcribe_progress, transcribe_complete)
        
        threading.Thread(target=transcribe_task).start()
    
    # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÉ‡∏ô‡πÄ‡∏ò‡∏£‡∏î‡πÅ‡∏¢‡∏Å
    def download_task():
        download_multiple_audio(urls, download_progress, download_complete)
    
    threading.Thread(target=download_task).start()

def display_multiple_results(results):
    """‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå"""
    # ‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤
    transcript_text.config(state=tk.NORMAL)
    transcript_text.delete("1.0", tk.END)
    segments_listbox.delete(0, tk.END)
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå
    global segments_global
    segments_global = []
    
    for i, result in enumerate(results):
        filename = result['file']
        segments = result['segments']
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡πÑ‡∏ü‡∏•‡πå
        transcript_text.insert(tk.END, f"\nüìÅ ‡πÑ‡∏ü‡∏•‡πå {i+1}: {filename}\n")
        transcript_text.insert(tk.END, "=" * 80 + "\n")
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° segments
        for j, seg in enumerate(segments):
            start = seg.get('start', 0)
            end = seg.get('end', 0)
            text = seg.get('text', '').strip()
            
            segment_index = len(segments_global)
            segment_with_file = {
                'start': start,
                'end': end,
                'text': text,
                'file_index': i,
                'file_path': result['path'],
                'filename': filename
            }
            segments_global.append(segment_with_file)
            
            transcript_text.insert(tk.END, f"[{segment_index}] ({start:.2f}s - {end:.2f}s): {text}\n")
            segments_listbox.insert(tk.END, f"{segment_index}: [{filename}] {text}")
    
    transcript_text.config(state=tk.DISABLED)

def on_cut_click():
    """‡∏ï‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å segment ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå)"""
    selected = segments_listbox.curselection()
    if not selected:
        messagebox.showwarning("Warning", "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å segment ‡∏Å‡πà‡∏≠‡∏ô")
        return

    index = selected[0]
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏Å‡πà‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏´‡∏°‡πà
    if len(segments_global) > 0 and isinstance(segments_global[index], dict) and 'file_path' in segments_global[index]:
        # ‡∏£‡∏∞‡∏ö‡∏ö‡πÉ‡∏´‡∏°‡πà (multiple files)
        segment = segments_global[index]
        audio_path = segment['file_path']
        filename_prefix = f"cut_{segment['filename'].replace('.mp3', '')}"
        original_filename = segment['filename']
    else:
        # ‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏Å‡πà‡∏≤ (single file)
        segment = segments_global[index]
        audio_path = current_audio_path
        filename_prefix = "cut"
        original_filename = os.path.basename(audio_path) if audio_path else "unknown"
    
    # Dialog ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå
    filename = simpledialog.askstring(
        "‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå", 
        f"‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå mp3 ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏™‡πà‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•):\n‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥: {filename_prefix}_segment{index}"
    )
    if not filename:
        return

    # ‡∏ñ‡∏≤‡∏°‡∏ß‡πà‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    delete_original = messagebox.askyesno(
        "‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö?", 
        f"‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏ï‡∏±‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà?\n\n"
        f"‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö: {original_filename}\n"
        f"‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà: {filename}.mp3\n\n"
        f"‚ö†Ô∏è ‡∏´‡∏≤‡∏Å‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 'Yes' ‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏•‡∏ö‡∏ñ‡∏≤‡∏ß‡∏£!"
    )

    output_path = os.path.join(OUTPUT_FOLDER, f"{filename}.mp3")
    cut_audio_segment(audio_path, segment, output_path, delete_original)

def install_whisper_local():
    """‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Whisper Local"""
    def install_task():
        try:
            status_label.config(text="‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á openai-whisper...")
            window.update()
            subprocess.run(["pip", "install", "openai-whisper"], check=True)
            messagebox.showinfo("Success", "‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á openai-whisper ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢! ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏µ‡∏™‡∏ï‡∏≤‡∏£‡πå‡∏ó‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°")
        except subprocess.CalledProcessError as e:
            messagebox.showerror("Install Error", f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏î‡πâ\n{e}")
        finally:
            status_label.config(text="")
            window.update()
    
    threading.Thread(target=install_task).start()

# ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå
def cleanup_original_files():
    """‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏≠‡∏¢‡∏π‡πà"""
    try:
        files = [f for f in os.listdir(OUTPUT_FOLDER) if f.endswith(".mp3") and not f.startswith("cut_")]
        if not files:
            messagebox.showinfo("Cleanup", "‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡πÉ‡∏´‡πâ‡∏•‡∏ö")
            return
        
        response = messagebox.askyesno(
            "‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", 
            f"‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö {len(files)} ‡πÑ‡∏ü‡∏•‡πå\n‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏•‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà?\n\n‚ö†Ô∏è ‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏ó‡∏≥‡∏ô‡∏µ‡πâ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏¢‡πâ‡∏≠‡∏ô‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏î‡πâ!"
        )
        
        if response:
            deleted_count = 0
            for file in files:
                try:
                    os.remove(os.path.join(OUTPUT_FOLDER, file))
                    deleted_count += 1
                except Exception as e:
                    print(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡∏ö {file}: {e}")
            
            messagebox.showinfo("Cleanup Complete", f"‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢: {deleted_count}/{len(files)} ‡πÑ‡∏ü‡∏•‡πå")
    
    except Exception as e:
        messagebox.showerror("Cleanup Error", f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")

# GUI Setup
window = tk.Tk()
window.title("üéµ Multi-Platform Audio Transcription (Batch Processing)")
window.geometry("700x900")  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á

# API Key Section
api_frame = tk.Frame(window)
api_frame.pack(pady=5)

# Transcription Method Selection
method_frame = tk.Frame(window)
method_frame.pack(pady=10)
tk.Label(method_frame, text="‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á:", font=("Arial", 12, "bold")).pack()

transcription_method = tk.StringVar(value="enhanced")

# Radio buttons for transcription methods
methods_info = [
    ("enhanced", "OpenAI Enhanced (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥) - ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î", "#4CAF50"),
    ("openai", "OpenAI Standard - ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏î‡∏µ ‡πÄ‡∏£‡πá‡∏ß", "#2196F3"),
    ("local", f"Whisper Local (‡∏ü‡∏£‡∏µ) - {'‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ' if WHISPER_LOCAL_AVAILABLE else '‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á'}", "#FF9800")
]

for value, text, color in methods_info:
    rb = tk.Radiobutton(
        method_frame, 
        text=text, 
        variable=transcription_method, 
        value=value,
        font=("Arial", 10),
        fg=color,
        activeforeground=color
    )
    rb.pack(anchor=tk.W, padx=20)

# URL Input Section
url_frame = tk.Frame(window)
url_frame.pack(pady=5)

tk.Label(url_frame, text="üîó ‡πÉ‡∏™‡πà‡∏•‡∏¥‡∏á‡∏Å‡πå (‡∏´‡∏•‡∏≤‡∏¢‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÑ‡∏î‡πâ):", font=("Arial", 12, "bold")).pack()
tk.Label(url_frame, text="üî¥ YouTube ‚Ä¢ ‚ö´ TikTok ‚Ä¢ üåê ‡∏≠‡∏∑‡πà‡∏ô‡πÜ | ‡∏ß‡∏≤‡∏á‡∏ó‡∏µ‡∏•‡∏∞‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏ß‡πâ‡∏ô‡∏ß‡∏£‡∏£‡∏Ñ", font=("Arial", 9), fg="gray").pack()

# ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏à‡∏≤‡∏Å Entry ‡πÄ‡∏õ‡πá‡∏ô Text widget ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
url_entry = tk.Text(window, width=80, height=4, font=("Arial", 10))
url_entry.pack(pady=5)

# ‡πÄ‡∏û‡∏¥‡πà‡∏° placeholder text
placeholder_text = """‡∏ß‡∏≤‡∏á‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏•‡∏¥‡∏á‡∏Å‡πå):
https://www.youtube.com/watch?v=...
https://vm.tiktok.com/...
https://www.youtube.com/shorts/..."""

url_entry.insert("1.0", placeholder_text)
url_entry.bind('<FocusIn>', lambda e: url_entry.delete("1.0", tk.END) if url_entry.get("1.0", tk.END).strip().startswith("‡∏ß‡∏≤‡∏á") else None)

download_btn = tk.Button(window, text="üéØ ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏∏‡∏Å‡∏•‡∏¥‡∏á‡∏Å‡πå", command=on_download_click, bg="#4CAF50", fg="black", font=("Arial", 12, "bold"))
download_btn.pack(pady=10)

status_label = tk.Label(window, text="", font=("Arial", 10))
status_label.pack()

tk.Label(window, text="‡∏ú‡∏•‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á (Transcript):", font=("Arial", 12)).pack(pady=5)
transcript_text = ScrolledText(window, width=80, height=10, state=tk.DISABLED)  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á
transcript_text.pack()

tk.Label(window, text="‡πÄ‡∏•‡∏∑‡∏≠‡∏Å segment ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á:", font=("Arial", 12)).pack(pady=5)
segments_listbox = tk.Listbox(window, width=80, height=10)  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á
segments_listbox.pack()

cut_btn = tk.Button(window, text="‚úÇÔ∏è ‡∏ï‡∏±‡∏î‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á", command=on_cut_click, bg="#2196F3", fg="black", font=("Arial", 12))
cut_btn.pack(pady=10)

# ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏∏‡πà‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
cleanup_btn = tk.Button(window, text="üóëÔ∏è ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", command=cleanup_original_files, bg="#FF5722", fg="black", font=("Arial", 10))
cleanup_btn.pack(pady=5)

# Info Labels
info_frame = tk.Frame(window)
info_frame.pack(pady=5)


segments_global = []
all_results_global = []
current_audio_path = ""

window.mainloop()